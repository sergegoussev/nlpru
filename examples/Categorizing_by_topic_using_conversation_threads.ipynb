{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Categorization with converstation thread effects\n",
    "\n",
    "When detecting topics in a document, common ways include simple *keyword* matching, *topic modeling*, and many others. While this works fine for large text documents like news articles, applying this type of approach to social media data has a serious *methodological* flaw: posts are not isolated but usually part of a conversation thread. Hence if one post is detected as being on the topic, it is logical that another post that replies to it is also on the topic, however this second post might not have used the listened to *keywords* and hence was not tagged as on the topic. \n",
    "\n",
    "This notebook walks through the problem and shows how **nlpru**'s `Recategorize_topics` method by taking thread affects simplifies this analysis.\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem space \n",
    "\n",
    "On Twitter, we can say that there are 3 potential scenarios for tweets in the context of a convesation thread:\n",
    "![Conversation_thread_visual.PNG](Conversation_thread_visual.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Topics flow down in threads, not up**: the first scenario is quite simple -- a tweet replies to another tweet. So for instance, if **tweet 1** is categorized as being on a certain topic, then logically every replying tweet is also on the topic (**tweets 2-5**). \n",
    "    * If **tweet 3** is on the topic, then **tweet 4** is as well, but not the others (**1, 2, or 5**)\n",
    "    * *NOTE*: This is obviously a bit of a simplification and depends on how a topic is defined. A reply can be on a separate topic, especially if the topics being analyzed are quite close logically, then the transition is harder to determine. More on this later...\n",
    "    \n",
    "2. **Adding text/comment while retweeting also has to be taken into account**: if a user retweets a tweet, they have the option to *Retweet with comment* -- which has its own 'tweet' characteristics and is linked (and displayed) with the retweeted tweet as embedded below. In the Twitter API, the retweeted tweet is called a `quoted_status`. Hence if a *quoted tweet*, for instance **tweet 10** is categorized on the topic, then the *commenting tweet* or **tweet 9**, must also be on the topic; and\n",
    "   \n",
    "3. **As regularly retweeted tweets have their own unique tweet id, this also has to be taken into account**: Twitter stores a reply relationship in the original (i.e. retweeted) tweet, not the tweet that retweeted it. As we often investigate tweet topics by also including the tweets that retweeted others as copies of the original, we need to take this into account.\n",
    "    * In other words, say we want to create a picture of the topics that were discussed during a particular day. We would pull all the tweets and then pull all the retweets that were made during that day, and plot them by topic per hour. This means that we pull the `retweet tweet id`, `retweet created at`, and `retweeted tweet text`. In this case, we need to check if the retweeted tweet was a reply to another tweet that was determined to be on a specific topic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such we have 4 inputs:\n",
    "* the original tweets pre-categorized, for instance using the `nlpru.Keyword_Match` method;\n",
    "* a list of tweets that reply to other tweets: `list_replies = [('twtid','inreplytotwtid'),...]`;\n",
    "* a list of retweeted tweet ids that retweeted a previous tweet: `list_rts = [('twtid','rttwtid'),...]`; and\n",
    "* a list of quotes, i.e. when one tweet quoted another: `list_quotes = [('twtid','qttwtid'),...]`\n",
    "\n",
    "The output should be like the pre-categorized list of tweets, but the topic labels should be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, there are **two ways** to solve the problem:\n",
    "1. Using the tweets that **are categorized** about the topic\n",
    "    * In other words, for each tweet that is a about a topic, use the conversation thread linkages based on certain rules to tag all related or **downstream** tweets as also about the topic. This will mean that a conversation thread is *virtually* created for each tweet coded about the topic.\n",
    "2. The reverse, starting with the tweets **not categorized** as about the topic\n",
    "    * This approach will require an iteration through all uncategorized tweets, checking each that the rules and conversation thread linkages allow the tweet to be recategorized as about the topic. This step is repeated again and again until tweets are **no longer** being recategorized. \n",
    "    \n",
    "While we need a thorough test of efficiency to know for sure, option 1 requires building a conversation thread *object* first, and using it to categorize tweets. As this method does not currently exist, this will be done in a later section. *(Note, some like @fionapigott have created [conversation thread builders](https://github.com/fionapigott/conversation-builder), but they only work with *replies*, and not *quotes*, as there is often an interelation of quotes that starts separate conversation threads)*\n",
    "\n",
    "This workbook will hence follow the 2nd option in solving the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution will be based on the following steps/rules:\n",
    "1. Create a dictionary for each convesation relationship, such as `replies_dict = {'twtid':'inreplytotwtid',...}`\n",
    "2. Create a dictionary for all tweets within the sample, and a sub-dictionary that contains the necessary parameters (topic, etc). For instance `tweet_dict = {'twtid':{'topic':'protests','twt_text':'bla bla bla','userid':'123456'}, ...}`\n",
    "3. Iterate through all tweets **not** on the topic, and using the convesation relationships from #1, find the the tweets that each tweet refers to (i.e. the *parent* to the *child*)\n",
    "4. Use the dictionary of tweets and topics from #2, to check which topic the *parent* tweet is on, and if its on the topic, change the topic of the *child*\n",
    "5. Continue until no more tweets are recategorized with each loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The full code of the solution can be seen in the [conversation.py](../nlpru/conversation.py) file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! \n",
    "\n",
    "Now lets see how to use this method using **nlpru**. We first need to:\n",
    "1. Categorize some tweets about a topic (we duplicate the steps described in the [\n",
    "Topic categorization example](nlpru_topic_categorization_walkthrough.ipynb))\n",
    "2. Prepare the `replies`, `retweets`, and `quotes` lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get some data and pre-categorize tweets as about a topic\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to kremlin_tweets_db database\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nlpru import FindTopics\n",
    "\n",
    "from pysqlc import DB\n",
    "db = DB('kremlin_tweets_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_data__(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Collect the data -- as tweets and retweets are stored separately, collect via inner joins and then\n",
    "    use UNION to append. \n",
    "    \"\"\"\n",
    "    q = \"\"\"\n",
    "     SELECT \n",
    "        tmast.twttext as twttext,\n",
    "        tsamp.twtid,\n",
    "        tmast.userid, \n",
    "        twt_createdat, \n",
    "        imrev3\n",
    "    FROM samp_twts_all_rus_twts_str tsamp \n",
    "        INNER JOIN twt_Master tmast \n",
    "        ON tsamp.twtid=tmast.twtid\n",
    "\n",
    "        LEFT JOIN meta_all_users_communities com\n",
    "        ON tmast.userid=com.userid\n",
    "\n",
    "    WHERE tmast.twt_lang='ru'  \n",
    "    AND tmast.twt_createdat >= '{start}'\n",
    "    AND tmast.twt_createdat < '{end}'\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        tmast.twttext AS twttext,\n",
    "        tsamp.twtid,\n",
    "        trts.userid,\n",
    "        twt_createdat,\n",
    "        imrev3\n",
    "    FROM samp_twts_all_rus_twts_str tsamp\n",
    "        INNER JOIN twt_rtmaster trts\n",
    "        ON tsamp.twtid=trts.twtid\n",
    "        INNER JOIN twt_master tmast\n",
    "        ON trts.rttwtid=tmast.twtid\n",
    "        \n",
    "        LEFT JOIN meta_all_users_communities com\n",
    "        ON tmast.userid=com.userid\n",
    "\n",
    "    WHERE tmast.twt_lang='ru' \n",
    "    AND tmast.twt_createdat >= '{start}'\n",
    "    AND tmast.twt_createdat < '{end}';\n",
    "    \"\"\".format(start=start_date,\n",
    "               end=end_date)\n",
    "    raw = db.query(q)\n",
    "    print(\"There are {:,} tweets in the captured sample!\".format(len(raw)))\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify *March 26th* as the day we want to focus on ([the day of massive protests in Russia](https://en.wikipedia.org/wiki/2017%E2%80%932018_Russian_protests#26_March_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44,613 tweets in the captured sample!\n"
     ]
    }
   ],
   "source": [
    "start_date='2017-03-26'\n",
    "end_date='2017-03-27'\n",
    "raw = __get_data__(start_date=start_date, end_date=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add some keywords and classify this data as *about* a topic or *not* based on a match of **at least one** keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets say we pick the following keywords:\n",
    "keywords1 = \"россия, москва, митинг, навальный, задержать, против, акция, полицейский, димонответить, димон, протест, коррупция\"\n",
    "keywords = keywords1.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = FindTopics(\n",
    "    tweet_list=raw,\n",
    "    tweet_text_index=0,\n",
    "    tweet_id_index=1)\n",
    "r = T.Keyword_Match({'protests':keywords})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`r` is outputted as the following key-value *dictionary* pair:\n",
    "```python\n",
    "'tweet id': {\n",
    "    'clean_words': ['...list of clean words...'],\n",
    "      'other': [\n",
    "          'user id',\n",
    "           datetime.datetime(time stamp tweet created at),\n",
    "           int(community (imrev3))],\n",
    "      'text': '...text of the actual tweet...',\n",
    "      'topic': '...topic text label ...'\n",
    "      }\n",
    "```\n",
    "\n",
    "To check what proportion of tweets is on the topic, lets convert it to a dataframe and calculate %s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none detected</th>\n",
       "      <td>84.878508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protests</th>\n",
       "      <td>15.121492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index\n",
       "topic                   \n",
       "none detected  84.878508\n",
       "protests       15.121492"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(r, orient='index')\n",
    "df.reset_index(inplace=True)\n",
    "df[[\"index\",\"topic\"]].groupby(\"topic\").count()/df[\"index\"].count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, aprox 15% of them are categorized as being about the topic we picked based on keywords. \n",
    "\n",
    "-----------------------\n",
    "\n",
    "This is the benchmark -- from this, we can add conversation thread affects\n",
    "\n",
    "### 2. Prepare the conversation thread linkages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the *list of replies* for this sample and date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_q = \"\"\"\n",
    "SELECT \n",
    "    repl.twtid, \n",
    "    inreplytotwtid\n",
    "FROM meta_repliesmaster repl\n",
    "    INNER JOIN samp_twts_all_rus_twts_str samp\n",
    "    ON repl.twtid=samp.twtid\n",
    "    \n",
    "    INNER JOIN twt_master tm\n",
    "    ON tm.twtid=repl.twtid\n",
    "    \n",
    "WHERE tm.twt_createdat >= '{start_date}'\n",
    "AND tm.twt_createdat < '{end_date}'\n",
    "\"\"\".format(start_date=start_date, end_date=end_date)\n",
    "reply_list = db.query(repl_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the *retweets* for this sample and date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_q = \"\"\"\n",
    "SELECT \n",
    "    rt.twtid,\n",
    "    rttwtid\n",
    "FROM twt_rtmaster rt\n",
    "    INNER JOIN samp_twts_all_rus_twts_str samp\n",
    "    ON rt.twtid=samp.twtid\n",
    "    \n",
    "WHERE rt.rt_createdat >= '{start_date}'\n",
    "AND rt.rt_createdat < '{end_date}'\n",
    "\"\"\".format(start_date=start_date, end_date=end_date)\n",
    "retweet_list = db.query(retweet_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the *quotes* for this sample and the date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_q = \"\"\"\n",
    "SELECT \n",
    "    qt.twtid,\n",
    "    qttwtid\n",
    "FROM twt_qtmaster qt\n",
    "    INNER JOIN samp_twts_all_rus_twts_str samp\n",
    "    ON qt.twtid=samp.twtid\n",
    "    \n",
    "    INNER JOIN twt_master tm\n",
    "    ON tm.twtid=qt.twtid\n",
    "    \n",
    "WHERE tm.twt_createdat >= '{start_date}'\n",
    "AND tm.twt_createdat < '{end_date}'\n",
    "\"\"\".format(start_date=start_date, end_date=end_date)\n",
    "quote_list = db.query(quote_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Now that all data is assembled, lets try to run the model and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpru import Conversations\n",
    "\n",
    "c = Conversations(\n",
    "    reply_list=reply_list,\n",
    "    retweet_list=retweet_list,\n",
    "    quote_list=quote_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration completed, recategorized this round: 388\n",
      "2 iteration completed, recategorized this round: 17\n",
      "3 iteration completed, recategorized this round: 0\n"
     ]
    }
   ],
   "source": [
    "t = c.Recategorize_topics(topic_for_which_to_check=\"protests\", tweet_dict=r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that only 3 iterations were required -- in fact the last one wasn't even needed! \n",
    "\n",
    "On the first round 388 tweets needed recategorizing based on coversation affects. Only 17 were reclassified in the second round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none detected</th>\n",
       "      <td>83.970681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protests</th>\n",
       "      <td>16.029319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index\n",
       "topic                   \n",
       "none detected  83.970681\n",
       "protests       16.029319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_postconvos = pd.DataFrame.from_dict(t, orient='index')\n",
    "df_postconvos.reset_index(inplace=True)\n",
    "df_postconvos[[\"index\",\"topic\"]].groupby(\"topic\").count()/df_postconvos[\"index\"].count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method added 1 more percent of conversation that discussed the topic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

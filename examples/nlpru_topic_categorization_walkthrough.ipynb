{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic categorization example\n",
    "\n",
    "In this tutorial, I will show how keywords can be used to add topic categories to a set of tweets using [**nlpru**](https://github.com/sergegoussev/nlpru)\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import requirements. For data, I will use a sample collected from a Twitter via the [GET statuses/sample API endpoint](https://developer.twitter.com/en/docs/tweets/sample-realtime/overview/GET_statuse_sample) normalized and stored in a MySQL [database schema]((https://github.com/sergegoussev/Twitter_analysis/tree/master/SQL). The method to connect to the database and extract data will use the [**pysqlc**](https://github.com/sergegoussev/pysqlc) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to kremlin_tweets_db database\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from nlpru import Cleaner\n",
    "from nlpru import FindTopics\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk import FreqDist\n",
    "\n",
    "from pysqlc import DB\n",
    "db = DB('kremlin_tweets_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets extract some data. We will focus on a specific day captured by the *GET statuses/sample* method and saved in the `samp_twts_all_rus_twts_str` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_data__(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Collect the data -- as tweets and retweets are stored separately, collect via inner joins and then\n",
    "    use UNION to append. \n",
    "    \"\"\"\n",
    "    q = \"\"\"\n",
    "     SELECT \n",
    "        tmast.twttext as twttext,\n",
    "        tsamp.twtid,\n",
    "        tmast.userid, \n",
    "        twt_createdat, \n",
    "        imrev3\n",
    "    FROM samp_twts_all_rus_twts_str tsamp \n",
    "        INNER JOIN twt_Master tmast \n",
    "        ON tsamp.twtid=tmast.twtid\n",
    "\n",
    "        LEFT JOIN meta_all_users_communities com\n",
    "        ON tmast.userid=com.userid\n",
    "\n",
    "    WHERE tmast.twt_lang='ru'  \n",
    "    AND tmast.twt_createdat >= '{start}'\n",
    "    AND tmast.twt_createdat < '{end}'\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        tmast.twttext AS twttext,\n",
    "        tsamp.twtid,\n",
    "        trts.userid,\n",
    "        twt_createdat,\n",
    "        imrev3\n",
    "    FROM samp_twts_all_rus_twts_str tsamp\n",
    "        INNER JOIN twt_rtmaster trts\n",
    "        ON tsamp.twtid=trts.twtid\n",
    "        INNER JOIN twt_master tmast\n",
    "        ON trts.rttwtid=tmast.twtid\n",
    "        \n",
    "        LEFT JOIN meta_all_users_communities com\n",
    "        ON tmast.userid=com.userid\n",
    "\n",
    "    WHERE tmast.twt_lang='ru' \n",
    "    AND tmast.twt_createdat >= '{start}'\n",
    "    AND tmast.twt_createdat < '{end}';\n",
    "    \"\"\".format(start=start_date,\n",
    "               end=end_date)\n",
    "    raw = db.query(q)\n",
    "    print(\"There are {:,} tweets in the captured sample!\".format(len(raw)))\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify *March 26th* as the day we want to focus on ([the day of massive protests in Russia](https://en.wikipedia.org/wiki/2017%E2%80%932018_Russian_protests#26_March_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44,613 tweets in the captured sample!\n"
     ]
    }
   ],
   "source": [
    "start_date='2017-03-26'\n",
    "end_date='2017-03-27'\n",
    "raw = list(__get_data__(start_date=start_date, end_date=end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets pick a few keywords that would qualify for the protest action happening on this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets say we pick the following keywords:\n",
    "keywords1 = \"россия, москва, митинг, навальный, задержать, против, акция, полицейский, димонответить, димон, протест, коррупция\"\n",
    "keywords = keywords1.split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we call the `FindTopics` object and give it the necessary [*parameters*](https://github.com/sergegoussev/nlpru/blob/master/docs/methods.md#topic-analysis), namely the tweets that we want to classify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = FindTopics(\n",
    "    tweet_list=raw,\n",
    "    tweet_text_index=0,\n",
    "    tweet_id_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the method, i.e. `.Keyword_Match()` and specify the topics we want as a distionary-list pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = T.Keyword_Match({'protests':keywords})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! the output of `r` will be a dictionary with the following information:\n",
    "```\n",
    "'twtid':{\n",
    "'clean_words': ['list of clean words'],\n",
    " 'other': ['whatever other inputs you specified. In this case the tweet id and the created_at time stamp'],\n",
    " 'text': 'text of the actual tweet',\n",
    " 'topic': 'topic of the tweet as identified'}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

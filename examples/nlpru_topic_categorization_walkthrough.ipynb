{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic categorization example\n",
    "\n",
    "In this tutorial, I will show how keywords can be used to add topic categories to a set of tweets using [**nlpru**](https://github.com/sergegoussev/nlpru)\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import requirements. For data, I will use a sample collected from a Twitter via the [GET statuses/sample API endpoint](https://developer.twitter.com/en/docs/tweets/sample-realtime/overview/GET_statuse_sample) normalized and stored in a MySQL [database schema]((https://github.com/sergegoussev/Twitter_analysis/tree/master/SQL). The method to connect to the database and extract data will use the [**pysqlc**](https://github.com/sergegoussev/pysqlc) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to kremlin_tweets_db database\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nlpru import FindTopics\n",
    "\n",
    "from pysqlc import DB\n",
    "db = DB('kremlin_tweets_db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets extract some data. We will focus on a specific day captured by the *GET statuses/sample* method and saved in the `samp_twts_all_rus_twts_str` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_data__(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Collect the data -- as tweets and retweets are stored separately, collect via inner joins and then\n",
    "    use UNION to append. \n",
    "    \"\"\"\n",
    "    q = \"\"\"\n",
    "     SELECT \n",
    "        tmast.twttext as twttext,\n",
    "        tsamp.twtid,\n",
    "        tmast.userid, \n",
    "        twt_createdat, \n",
    "        imrev3\n",
    "    FROM samp_twts_all_rus_twts_str tsamp \n",
    "        INNER JOIN twt_Master tmast \n",
    "        ON tsamp.twtid=tmast.twtid\n",
    "\n",
    "        LEFT JOIN meta_all_users_communities com\n",
    "        ON tmast.userid=com.userid\n",
    "\n",
    "    WHERE tmast.twt_lang='ru'  \n",
    "    AND tmast.twt_createdat >= '{start}'\n",
    "    AND tmast.twt_createdat < '{end}'\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        tmast.twttext AS twttext,\n",
    "        tsamp.twtid,\n",
    "        trts.userid,\n",
    "        twt_createdat,\n",
    "        imrev3\n",
    "    FROM samp_twts_all_rus_twts_str tsamp\n",
    "        INNER JOIN twt_rtmaster trts\n",
    "        ON tsamp.twtid=trts.twtid\n",
    "        INNER JOIN twt_master tmast\n",
    "        ON trts.rttwtid=tmast.twtid\n",
    "        \n",
    "        LEFT JOIN meta_all_users_communities com\n",
    "        ON tmast.userid=com.userid\n",
    "\n",
    "    WHERE tmast.twt_lang='ru' \n",
    "    AND tmast.twt_createdat >= '{start}'\n",
    "    AND tmast.twt_createdat < '{end}';\n",
    "    \"\"\".format(start=start_date,\n",
    "               end=end_date)\n",
    "    raw = db.query(q)\n",
    "    print(\"There are {:,} tweets in the captured sample!\".format(len(raw)))\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify *March 26th* as the day we want to focus on ([the day of massive protests in Russia](https://en.wikipedia.org/wiki/2017%E2%80%932018_Russian_protests#26_March_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44,613 tweets in the captured sample!\n"
     ]
    }
   ],
   "source": [
    "start_date='2017-03-26'\n",
    "end_date='2017-03-27'\n",
    "raw = list(__get_data__(start_date=start_date, end_date=end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets pick a few keywords that would qualify for the protest action happening on this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets say we pick the following keywords:\n",
    "keywords1 = \"россия, москва, митинг, навальный, задержать, против, акция, полицейский, димонответить, димон, протест, коррупция\"\n",
    "keywords = keywords1.split(\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we call the `FindTopics` object and give it the necessary [*parameters*](https://github.com/sergegoussev/nlpru/blob/master/docs/methods.md#topic-analysis), namely the tweets that we want to classify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = FindTopics(\n",
    "    tweet_list=raw,\n",
    "    tweet_text_index=0,\n",
    "    tweet_id_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the method, i.e. `.Keyword_Match()` and specify the topics we want as a distionary-list pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = T.Keyword_Match({'protests':keywords})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! the output of `r` will be a dictionary with the following information:\n",
    "```python\n",
    "'twtid':{\n",
    "    'clean_words': ['list of clean words'],\n",
    "    'other': ['whatever other inputs you specified. In this case the tweet id and the created_at time stamp'],\n",
    "    'text': 'text of the actual tweet',\n",
    "    'topic': 'topic of the tweet as identified'\n",
    "}\n",
    "```\n",
    "\n",
    "Or in our case:\n",
    "\n",
    "```python\n",
    "'tweet id': {\n",
    "    'clean_words': ['...list of clean words...'],\n",
    "      'other': [\n",
    "          'user id',\n",
    "           datetime.datetime(time stamp tweet created at),\n",
    "           int(community (imrev3))],\n",
    "      'text': '...text of the actual tweet...',\n",
    "      'topic': '...topic text label ...'\n",
    "      }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none detected</th>\n",
       "      <td>84.878508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protests</th>\n",
       "      <td>15.121492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   index\n",
       "topic                   \n",
       "none detected  84.878508\n",
       "protests       15.121492"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(r, orient='index')\n",
    "df.reset_index(inplace=True)\n",
    "df[[\"index\",\"topic\"]].groupby(\"topic\").count()/df[\"index\"].count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Using the keyword method, we have now detected that slightly over 15% of our tweets were on the topic we were listening for!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
